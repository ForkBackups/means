\section{Results and Discussion} \label{results}



\subsection{Performance}\label{performance}
The temporal dynamics of a molecular system can be described by the \acrfull{cme}\cite{kampen_stochastic_2011}.
\acrfull{gssa}\cite{gillespie_general_1976} simulates these stochastic dynamics directly returning a set of individual trajectories for a list of particles observed.
In order to obtain accurate estimates of the average dynamic within a population of cell (\ie{} the mean dynamics), it is however necessary to perform multiple (often more than $10^4$) simulations.
Despite recent efforts \cite{niemi_efficient_2011,dittamo_optimized_2009,komarov_accelerating_2012} to provide fast implementation of this algorithm, computation remains extremely expensive. 
This time-complexity is a limiting factor in downstream analysis techniques, for
instance parameter inference that often requires repetition of these experiments for a large set of parameter values.

This particular limitation led to the development of approximations such as \acrfull{lna}\cite{komorowski_bayesian_2009} and \acrfull{mea}\cite{ale_general_2013}
 which model the mean behaviour directly, without evaluating the individual particle behaviours, and therefore can perform in a more realistic time.

Since the main driving force for development of these approximation algorithms is the potential reduction of the time taken to perform the analysis, 
it is paramount to make the implementation as efficient as possible.

In this section, we explore the implementation factors that influence the runtime of the algorithm, and describe the optimisations done to increase the its performance.
In particular, we show that symbolic computations can be limiting the algorithm and explain the techniques used to optimised them.
We also quantify the increase in performance we achieved and show that it is several orders of magnitude faster than the original \mat{} prototype.
In addition, we explore other limiting factors we have less control of, such as the choice of \gls{ode} solver, and discuss their potential implications to the analysis of biological systems.

\subsubsection{Optimising \acrlong{mea}}
\label{sec:optimising_mea}

\gls{mea} involves derivation of a system \gls{ode}s from a model.
This procedure\cite{ale_general_2013}, involves lengthy symbolic calculations.
Even for very simple models (\eg{} three species, five reactions), they cannot be realised manually.
The number equations in the generated \gls{ode} system, for a model with $s$ species and up to moments of order $o$ can be estimated by the following equation: 
\begin{equation}
    \text{Number of equations} = {{s + o} \choose {s}} - 1
    \label{eq:number_of_equations}
\end{equation}
As a consequence, the complexity of the calculation is predicted to increase exponentially with the number of species in the system and the maximal order of moments. 
For example, in a system with five species, performing \gls{mea} up to moments of order 2, 3, 4 and 5, results in an \gls{ode} system with 20, 55, 125 and 251 equations, respectively. 

%In order to perform symbolic computations, we have used \sympy{} \cite{sympy_development_team_sympy:_2014}; a \py{} implementation of
%the symbolic computation routines.

In order to increase the scalability of the method, we have identified significant bottlenecks in our procedures using \py{} profiling tools.
We have then attempted to iteratively remove these bottlenecks one by one. Figure~\ref{fig:mea_speed} shows the cumulative effects of different optimisations.
The performance assessment were realised on algorithm when performing log-normal closure in order to show the effect of improvements specific to parametric closure (fig.~\ref{fig:mea_speed}d). 

\begin{figure}[tbh]

\includegraphics[width=0.95\textwidth{}]{../figure_mea_speed/mea_speed.pdf}
\caption{\emph{Cumulative performance improvement of symbolic 
calculations resulting from optimisation}.
The processing time for computing log-normal closure on \pft{} model with different maximal moment orders were measured for original Matlab implementation (a) and different optimisations (b$-$f).
In a first place, the calls to \texttt{sympy.simplify()} where removed (b). 
Then, \texttt{sympy.xreplace()} was used instead of \texttt{sympy.substitute()} (c). 
Generating an $(n-s) \times (n_2-s + 1)$ matrix (d), as opposed to an $(n-s) \times (n-s + 1)$ one, also increase speed.
Implementing a simplified equation solver instead of using \texttt{sympy.solve()} also resulted in a significant speed-up (e). 
Finally, caching (memorisation) \texttt{sympy.diff()} allowed even better performance.
The time complexity appears exponential ($O(2^n)$, where $n$ is the maximal moments order) in every case, 
%Interestingly, the slopes between, a ($0.95$) and c ($0.58$), and b ($0.62$) and c were significantly different ($p-value <10^{-15}$ and $p-value = 3 \times 10^{-4}$, respectively; t-test on the slopes of the linear regression). 
%No significant difference was found between the slopes of the subsequent optimisations (c$-$f). 
%However, the intercepts were significantly smaller between each consecutive optimisations after c) ($p-value < 10^{-6}$ for all; t-test on the intercepts of the linear regression).
Nine replicates were performed on the same CPU. 
For optimisation c$-$f, values corresponding to maximal order moments lower than two were removed because of the inherent inaccuracy in measuring very short durations.
}
\label{fig:mea_speed}
\end{figure}

\quentintodo{move the stats here}

Reorganising, profiling and rewriting the code resulted in incremental significant performance improvements of symbolic computations in \means{} compared to the original \mat{} code.
For instance, with the same \pft{} system and closure method, 
we predict that computation up to \gls{ode}s up $8^{th}$ order will take 46 minutes with \means{}, 5 hours after the first optimisation (fig.~\ref{fig:mea_speed}b) and as much as 148 days with the original implementation.
These improvement have allowed us to explore the performance of MEA in higher depth, and will hopefully contribute to make \gls{mea} realistically usable for systems with more species and reactions.

\subsubsection{Evaluating Expressions Efficiently}

As mentioned in the introduction to this section, the reduction of computational cost was the main reason for developing of approximation methods.
In order to be able to explore the approximation methods in more depth,
we needed to make the generation of the set of equations as efficient as possible, as mentioned in the previous section.

Generating a set of equations (\ie{} and \gls{ode} problem) is generally only the first step.
In most cases, the result is used to perform simulations with different parameters.
As a consequence, the same \gls{ode} problem will be generated once, and used many times.
Typically, a user would spend some time to generate an set of equation using \gls{mea}, and then use this \gls{ode} problem to perform hundreds of simulations.
Therefore, it was extremely important to assess and try to improve numerical evaluation performance.
 
%Even though it is a great improvement from the original prototype, 46 minutes is still a long time to wait for the computer to do the number crunching. 
%We can accept to wait this long, however, as we only need to do that once for a set of equations -- the next time we intend to do that, we can just read the previous set from a file.

%Evaluating these expressions is a completely different story however.
%Since we need to evaluate each expression hundreds, if not thousands of times when performing the simulations of the system,
% we want to make these tasks as efficient as possible, as every microsecond counts. 

In order to minimise the overhead of computations, we use the {\tt autowrap} module, built into {\tt sympy} to compile our numeric expressions into \texttt{C}
and then wrap the same \py{} interface around them so the end user does not see any difference.
This process bears some overhead, of course, as the system needs to be compiled for every simulation.

We notice that the expressions for a given set of equation could be compiled once and reused for all subsequent simulations on this set of equations.
Therefore, we used caching to keep precompiled expressions in memory.
 
As a consequence, the overhead is present only in the first evaluation of expressions, whilst all other evaluations are an order of magnitude faster.
This performance improvement is illustrated in the tutorial \autoref{sec:reuse_of_simulation_objects}.

\subsubsection{Comparing the Performance of Different \gls{ode} Solvers}

The symbolic expression evaluation speed, whilst incredibly important, contributes only partially to the scalability of the simulation procedures.
The performance of numerical \gls{ode} solvers themselves also plays a critical role.

These solvers differ in many ways ranging from a set of parameters to different heuristics and even algorithms.
Choice of the \emph{best} solver for an \acrlongpl{ode} system depends very much on the particular problem to simulate.
However certain solvers tend to be more generally adopted than others\cite{andersson_workbench_2012}.

CVODE\cite{hindmarsh_sundials_2005} is an example of one of the most widely used solvers.
As described in \autoref{sec:ode_simulations}, we implement two variants of this solver, \verb#ode15s# and \verb#cvode#.
Both solvers point to the same back-end implementation of CVODE provided by \verb#assimulo# package\cite{andersson_christian_assimulo:_????}.
The only diference is that \verb#ode15s# solver's default parameters mimics the eponymous \mat{} solver.

In order to measure the runtime performance of the solvers, we performed a set of simulations of the \acrlong{mea} of the \pft{} model.
We deliberately chose two sets of parameters: one that we know is fairly stable and easy to simulate with, so called \emph{safe} parameter set,
and another parameter set that is known to cause the trajectories to become stiff and therefore cause problems to the solvers.
We call the latter parameter set the \emph{unsafe}.
 
\begin{figure}[tb]
   \centering
   \begin{subfigure}[t]{0.45\textwidth}
       \includegraphics[width=\textwidth]{../pipeline/task-output/solver-runtimes/runtimes-ode15s.pdf}
       \caption{\texttt{ode15s}}
       \label{fig:runtimes-safe-unsafe-ode15s}
   \end{subfigure}
   ~
   \begin{subfigure}[t]{0.45\textwidth}
       \includegraphics[width=\textwidth]{../pipeline/task-output/solver-runtimes/runtimes-euler.pdf}
       \caption{Euler}
       \label{fig:runtimes-safe-unsafe-euler}
   \end{subfigure}
   
    \caption{Comparison of the time taken for the {\tt ode15s} and Euler solvers to simulate a system, with respect to two parameter sets, one harder to simulate than the other as it makes the problem stiff.
    The time axis is in log-scale. Regression lines through the marked points is represented.
    Note that the number of equations increases exponentially with maximum order, essentially making this a log-log plot.}
\label{fig:runtimes-safe-unsafe}
\end{figure}

\texttt{ode15s} solver was more performant for the safe parameter set (fig.~\ref{fig:runtimes-safe-unsafe-ode15s}).
Heuristic solvers tend to automatically adjust the step size depending on the problem in hand, adjusting for the rate of stochastic events being simulated.
It is therefore expected that they would perform worse for stiff problems, where the timeframes between the events become shorter and shorter, which requires more time steps.

In contrast, Euler solver, uses a constant step size, and therefore the runtimes for the two parameter sets are equal (\autoref{fig:runtimes-safe-unsafe-euler}).

Since \gls{ode} solvers are inherently heuristic, their CPU performance may suffer considerably for unstable systems.

Besides CVODE solvers, our package is able to perform simulations with seven other solvers, using completely different algorithms.
The complete list of available solvers used in available in the documentation\citationneeded{refer to docs}.
Naturally, we were then interested in assessing, in the same fashion, all nine available solvers for these two parameter sets (\autoref{fig:solver-runtimes}).
This exhaustive analysis reviled that \texttt{ode15s} was the most performant solver for this problem.
It outperformed other solvers for both safe and unsafe parameter sets.
Interestingly, \texttt{dopri5} appeared to scale better for unsafe parameter sets, and could be interesting when working with high maximal moment orders.
Surprisingly, \texttt{rodas}, which has been described as an very competitive solver for stiff \gls{ode}\cite{sandu_benchmarking_1997},
performed poorly on this case.

Using an appropriate solver can improve numerical performance by an order of magnitude (\autoref{fig:solver-runtimes}).
Therefore, we advise users to benchmark different solvers on their specific problems if numerical evaluation speed is critical (\ie{} for parameter inference).
In addition, advanced users can optimise the numerous options of each solvers in order improve performance.
Although we cannot conclude that \texttt{ode15s} is the fastest solver for all \gls{mea} problems,
it seems to be a reasonable default solver.

\begin{figure}[bt]
    \centering
    \includegraphics[width=\textwidth]{../pipeline/task-output/solver-runtimes/runtimes-all.pdf}
    \caption{\emph{Comparison of all solver runtimes.}
    The runtime of nine different solvers were compared for a safe (left side) and an unsafe (right side) parameter set.
    Regression lines through the marked points is represented in a different colour for each solver.
    Solvers are sorted, top to bottom, by increasing performance in the legend.
    \texttt{ode15s} was globally the fastest solver.
    }
    \label{fig:solver-runtimes}
\end{figure}


In order to improve performance, we have compared solvers on the basis of their speed.
However, they also differ in their accuracy and stability. 
In fact, most solvers trade-off accuracy and speed\cite{sandu_benchmarking_1997}.
This was investigated in  \sauliustodo{ref to new section once I create it}.

\subsection{Moment Expansion Closure}

In \gls{mea} the time derivative of each central moment is expressed in terms of the higher order moment.
This behaviour has no upper bound and continues up to moments of infinite order.
Since we cannot evaluate these expressions in the limit analytically, it is necessary to ``close'' the expansion by providing a closed form for the higher order moments.
This also makes the method an ``approximation" rather than an exact method.

In the original work \cite{ale_general_2013}, higher order central moments are assumed to be equal to zero.
This is very convenient, but remains a strong and not necessarily valid assumption.

As an alternative, parametric probability distribution can be used to express moments of arbitrary orders.
For instance, a multivariate normal distribution is parametrised only by means (\ie{} first order raw moment)
and a covariance matrix (\ie{} second order central moments).
As a consequence, it is possible to express any arbitrary moment from means, variances and covariances.
A promising area of research involves closing moment expansion by parametric forms for highest order central moments (instead of assuming them to be null).
Preliminary work \cite{lakatos_preparation_2014} suggests that using a parametric distributions for \gls{mea} is, in some cases, a better approximation.
In addition, Ale \emph{et al.} predicted that ``including more moments would improve the estimation''\cite{ale_general_2013}.

The dramatic improvement in performance compared to the \mat{} prototype (see \autoref{sec:optimising_mea}) has rendered the exploration of higher-order and parametric moment closures possible.
Therefore, we were naturaly interested in investigating the effect of maximal moment order and different type of closures on the quality of the approximation.
Figure~\ref{fig:max_order_and_closure_on_distance_summary} summarises our results on the \pft{} model. 
The detail of generated trajectories for two representative maximal orders and one species are shown in
\autoref{fig:max_order_and_closure_on_distance_trajectories}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{../pipeline/task-output/FigureP53Summary/FigureP53Summary-pdf-7.pdf}
    \caption{\emph{Effect of different closure methods and maximal moment order on simulation accuracy}. The \pft{} system was modelled using \gls{mea} with five types of closure and for maximal moment order up to seven.
Resulting trajectories were all compared to an average of 5000 \gls{gssa} simulations using sum of square distance.
Distance is in log scale. Missing values indicate solver failure for that particular set of parameters.}
    \label{fig:max_order_and_closure_on_distance_summary}
\end{figure}

The \pft{} system, with parameters from \cite{ale_general_2013}, was investigated.
As mentioned above approximation accuracy is expected to increase with the maximal moment order, \ie{} distance to \gls{gssa} obtained should decreases
 as maximal moment order increases.
For normal and scalar closures, we observe this trend up to maximal moment order six.
However, this does not stand for seventh order moment.

Normal distribution closure, with maximum order of seven, performed worse than the sixth order and fith order for the same closure (fig.~\ref{fig:max_order_and_closure_on_distance_summary}).
We could not obtain the result for the seventh order closure using the standard scalar and univariate normal closure
because the ODE solver failed to simulate the problem.
This usually indicates a ``stiff'' \gls{ode} problem\citationneeded{stiff odes}.
In this case, the trajectories generated seem to `mismatch' the trajectory obtained from the \gls{gssa} simulations by
large a margin (fig.~\ref{fig:max_order_and_closure_on_distance_trajectories}, right panel).
% (\emph{purple line, subplot on the right-hand-side}).

The reason for this behaviour is uncertain. It could either be a limitation of the approximation method, or a numerical limitation of the available \gls{ode} solver.
It is hard to know which explanation is more likely since we cannot test the two hypotheses separately.
Interestingly, we observed a similar behaviour with all of the solvers tested, which is further explored in \sauliustodo{link to my section where we study the phenomenon on larger scale with different solvers}.

Note that for even maximal moment orders, normal and scalar are identical.
When the maximal moment order is even, it means that the parametric expression of an odd (the next) order moment was used for closure.
Normal distribution is symmetrical. One consequence is that odd central moments are always zero.
For instance, the sckew (\ie{} third order central moment) of a normal distribution is zero.
Therefore, this behaviour is perfecty normal.


\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{../pipeline/task-output/FigureP53Simple/FigureP53Simple-pdf-7.pdf}
%~
    \caption{\emph{Complete trajectories of a single species (\pft) for max order three and seven are shown} 
    Black lines indicate the average of \gls{gssa} simulations. 
    Missing lines, compared to the legend in \autoref{fig:max_order_and_closure_on_distance_summary} indicate solver failure.}
    \label{fig:max_order_and_closure_on_distance_trajectories}
\end{figure}

 
For log-normal closure, the ground-truth trajectory seems to be well approximated when the maximal moment order is three.
However the approximation becomes less and less accurate for higher maximal order moments.
A deeper look at the trajectories indicate that, in this latter case,
oscillations are damped too quickly. (fig.~\ref{fig:max_order_and_closure_on_distance_trajectories}, red lines, right panel).
This contrasts with normal closure, where the oscillation amplitude increases.

Interestingly, for even maximum moment order (\ie{} 2, 4, 6) log-normal closures generated \gls{ode}s which, despite our efforts, could not be numerically solved.

Finally, it seems that the results obtained from multivariate distribution closures and univariate distribution closures,
 which do not model the covariance terms, are the similar for this particular system.
This is not true for all of the systems.
For instance, we have observed that in the \emph{hes1}, it is advantageous to model covariance (data not show).
\quentintodo{put hes1 exple if time}

Surprisingly, higher order moment closure did not necessarily result in better approximations.
In addition, our results indicate that there might be a complex interaction between the type of closure and the maximal moment order.
Unfortunately, this makes it difficult to define \emph{a priori} which closure and maximal moment order should be used for a given system.
These unexpected results lead us explores this phenomenon on wider scale of parameters\sauliustodo{link to the section}.

\subsection{Parameter Inference using \acrlong{mea}}
Parameter inference procedure aims to obtain the correct parameter values for the system by exploring the parameter space and comparing the simulation trajectories with the experimental data.

%In order to study the performance of the parameter inference procedure using \acrlong{mea}, we took the average trajectory obtained from the  $5000$ \gls{gssa} simulations of the \pft{} with a certain parameter set and used it as the observed dataset we want to infer the parameters from. Essentially, the inference procedure is expected to return the said parameter set back to us.
In order to study the performance of the parameter inference procedure using \acrlong{mea},
we generated $5000$ \acrfull{gssa} simulations of the \pft{} with a certain parameter set. We believe this number of \gls{gssa} simulations to be sufficient to capture the behaviour of this model system in full.
Then, we used the average as an observed dataset from which to infer parameters.
In this way, we know exactly what are the ``true'' parameters for every inference procedure we perform.

In order to determine the base case performance, we performed the parameter inference using the \pft{} model expressed only in terms of the first order moments (see \autoref{fig:7_dimensional_parameter_space}).
This approximation is bound to be very inaccurate for the particular system, as higher order moments are necessary to capture the damped oscillations present in the means of \gls{gssa} simulations\cite{ale_general_2013}.


%\begin{figure}
%\centering
%\includegraphics[width=0.9\textwidth]{{../pipeline/task-output/SevenDimensionalInferenceFigure/SevenDimensionalInferenceFigure-pdf-ode15s--sum_of_squares-5000}.pdf}
%\caption{\emph{Distance landscape based on inference using all the parameters in \pft{} model.}
%In the parameter inference procedure, all seven parameters were free and started from the correct values.
%The parameters are aligned both horizontally and vertically to display the distance landscape obtained by comparing inferred trajectories with \gls{gssa} trajectories.}
%\label{fig:7_dimensional_parameter_space}
%\end{figure}


The starting parameters were the correct ones, so we expected immediate convergence (\ie{} no movement in the parameter space).
Surprisingly, when parameters are free, inference was able to find a set of parameters, mind very different from the ``correct" ones, for which observed and theoretical trajectories are extremely similar.\sisitodo{Can you add a figure showing how similar they are here?}
This result was unexpected, because, as mentioned previously, higher order moments are believed to be necessary to capture the complex behaviour of the system.


%\sisitodo[inline]{Why don't we compare the SSA trajectories with these parameters somewhere as well, if there is time?}

In order to gain some insight into these unexpected inference results, we first attempted to restrict ourselves to, easier to comprehend, two-dimensional space.
To do this, we restricted our parameter inference procedure to only have only a pair of free parameters at a time (all other parameters are fixed to their true values).
We performed this for all combinations of two parameters and checked if we can reproduce the curious behaviour.

\begin{figure}[tb]
    \centering
    \begin{subfigure}[t]{0.9\textwidth}
    \includegraphics[width=\textwidth, height=0.18\textheight]{{../pipeline/task-output/FigureInferenceStartEndSSA/Paired-parameters-c2-c6}.pdf}
    \label{fig:parameter_pair_c2_c6}
    \caption{Parameter pair $c_2$ and $c_6$}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.9\textwidth}
    \includegraphics[width=\textwidth, height=0.18\textheight]{{../pipeline/task-output/FigureInferenceStartEndSSA/Paired-parameters-c0-c1}.pdf}
    \label{fig:parameter_pair_c0_c1}
    \caption{Parameter pair $c_0$ and $c_1$}
    \end{subfigure}
    ~
    \caption{\emph{Two out of four parameter pairs that can produce a perfect match between inferred optimal trajectories and SSA trajectories for all species in \pft{} model.}
    The distance from the SSA trajectory for each species is displayed in each subfigure.
    Trajectories are simulated using maximum order 1. The three columns in each row represent the three species in the \pft{} model.}
    \label{fig:parameter_pairs}
\end{figure}

Interestingly, we were able to observe the same behaviour for the parameter pairs $c_2$ and $c_6$, $c_0$ and $c_1$, $c_1$ and $c_6$, and finally $c_0$ and $c_6$ (first two pictured in the\autoref{fig:parameter_pairs}).
We then have chosen the pair of parameters that allowed the inference procedure to converge to a trajectory with minimal distance to the stochastic average -- $c_2$ and $c_6$ for further investigations.
\sisitodo[inline]{Change the figures to show one of the species for the plots, not all three -- the information is redundant now, and this would allow to make them larger while using the same space on the page}

\sisitodo[inline]{Unify the height of the two figures}
\begin{figure}
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/SampleMultidimensionInferenceFigure/SampleMultidimensionInferenceFigure-pdf-1-scalar-True-90.0_0.002_1.704_1.1_0.93_0.96_0.7822-ode15s--90.0_0.002_1.704_1.1_0.93_0.96_0.7822-sum_of_squares-5000}.pdf}
    \caption{Distance Landscape}
    \label{fig:inference_phenomenon:maxorder:1:landscape}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.65\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/FigureInferenceStartEndSSA/FigureInferenceStartEndSSA-1-scalar-c2-1.7040-c6-0.7822}.pdf}
    \caption{Trajectories}
    \label{fig:inference_phenomenon:maxorder:1:trajectories}
    \end{subfigure}
    \caption{The distance landscapes and observed trajectories for the parameter inference performed for first order moment expansion approximation}
    \label{fig:inference_phenomenon:maxorder:1}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.2\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/SampleMultidimensionInferenceFigure/SampleMultidimensionInferenceFigure-pdf-2-scalar-True-90.0_0.002_1.704_1.1_0.93_0.96_0.7822-ode15s--90.0_0.002_1.704_1.1_0.93_0.96_0.7822-sum_of_squares-5000}.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.6\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/FigureInferenceStartEndSSA/FigureInferenceStartEndSSA-2-scalar-c2-1.7040-c6-0.7822}.pdf}
    \end{subfigure}   
    ~
    \begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/SampleMultidimensionInferenceFigure/SampleMultidimensionInferenceFigure-pdf-3-scalar-True-90.0_0.002_1.704_1.1_0.93_0.96_0.7822-ode15s--90.0_0.002_1.704_1.1_0.93_0.96_0.7822-sum_of_squares-5000}.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.6\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/FigureInferenceStartEndSSA/FigureInferenceStartEndSSA-3-scalar-c2-1.7040-c6-0.7822}.pdf}
    \end{subfigure}   
     ~  
    \begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/SampleMultidimensionInferenceFigure/SampleMultidimensionInferenceFigure-pdf-4-scalar-True-90.0_0.002_1.704_1.1_0.93_0.96_0.7822-ode15s--90.0_0.002_1.704_1.1_0.93_0.96_0.7822-sum_of_squares-5000}.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.6\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/FigureInferenceStartEndSSA/FigureInferenceStartEndSSA-4-scalar-c2-1.7040-c6-0.7822}.pdf}
    \end{subfigure}   
   
    \begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/SampleMultidimensionInferenceFigure/SampleMultidimensionInferenceFigure-pdf-5-scalar-True-90.0_0.002_1.704_1.1_0.93_0.96_0.7822-ode15s--90.0_0.002_1.704_1.1_0.93_0.96_0.7822-sum_of_squares-5000}.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.6\textwidth}
    \includegraphics[width=\textwidth]{{../pipeline/task-output/FigureInferenceStartEndSSA/FigureInferenceStartEndSSA-5-scalar-c2-1.7040-c6-0.7822}.pdf}
    \end{subfigure}
   
\caption{\emph{Distance landscape and trajectories at different maximal orders for \pft{} model.}  Among seven parameters, only the values for $c_2$ and $c_6$ are inferred, with starting values inferred from inference using the true values.
The left column displays distance landscapes, the warmer the colour, the more distant the inferred trajectories are from the \gls{gssa} trajectories.
The numbers in the distance landscape indicate the distance between optimal trajectories obtained from inference and the \gls{gssa} trajectories.
The \gls{gssa} trajectories are generated using the new parameter values labelled as \emph{start}.
Three trajectories are shown for each species.
The starting trajectories are simulated using the starting values are indicated above the trajectories, with $c_2$ and $c_6$ inferred using \emph{sum of squares} distance method.
Both the optimal and the \gls{gssa} trajectories are generated based on the end point in correspondent distance landscape.
The distance displayed for each species represent the distance between the optimal and \gls{gssa} trajectories.}
\label{fig:parameter_inference_landscape_trajectories}
\end{figure}

\sisitodo[inline]{I do not like the way the subsequent paragraphs were worded as they do not tell the reader anything and pretty much are "look at the figure yourself. I rewrote part of the text to try to explain a couple of things we want to explain. Read through it, and see if you can add anything.}

In order to understand this phenomenon, we aimed to explore the distance landscape of the particular problem. As one can see from the distance landscape pictured in \autoref{fig:inference_phenomenon:maxorder:1:landscape}, the parameter inference starts in a high-distance zone, which is expected as \gls{mea} cannot capture the damped oscillatory behaviour of the system for this set of parameters without higher order moments, as illustrated by the starting trajectories in \autoref{fig:inference_phenomenon:maxorder:1:trajectories}. 
What is surprising to observe, however, that the landscape is not relatively level \ie{} the approximation is not equally bad for all parameter sets. There is a clear pool of parameters, where no high-order information is needed to approximate this oscillatory behaviour.

We then moved on to explore this behaviour for the higher-order \gls{mea} approximations. We were able to observe that the starting trajectory becomes closer to the real trajectory as we increase the maximum order of the moments, with the best results when the moments were closed at the maximum order of three. 
We can also see that the distance landscapes become more and more level for higher order moments, however, the parameter inference process still not stationary and able to  drift away from the correct set of parameters. The complete set of observations is provided in \autoref{fig:parameter_inference_landscape_trajectories}.

\sisitodo[inline]{Fix the big figure so you can refer to individual parts from text}
\sisitodo[inline]{Didn't we look at log normal closure/even higher order moments, I don't remember that much blue!}

In conclusion, we do not seem to be able to recover the correct parameter set even in the best case, when the parameter inference does not need to do any work at all. 
This observation raises concerns about the validity of parameter inference approaches using \gls{mea} approximation. 
