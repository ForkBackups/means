\section{Introduction} \label{intro}

Most biological systems, such as cells, organisms, populations and ecosystems are intrinsically complex and non-linear.
For this reason, some aspects of these systems are extremely difficult to understand and predict, both qualitatively and quantitatively\cite{klipp_systems_2013}.
Explicit models describing these systems provide an abstract and extensible framework which allows to infer the state of a system from experimental data.
In addition, models allow to make testable predictions about the behaviour of the system in response to some stimuli.
In the last a few decades, use of mathematical representations of biological interactions has been an increasingly fruitful and wide aspect of biological research.
Many areas of biology, such as ecology, population biology and biochemistry, now
use kinetic modelling to describe and understand temporal dynamics of their respective systems.
Deterministic modelling of dynamic systems generally involves listing
interacting agents (species) and decomposing a system in individual processes (\eg{} chemical reactions).
Processes are mathematically described with explicit rate parameters, and \acrfullpl{ode} are used to express the change in the amount of species over time.
Generally, systems are assumed to be homogeneous, and the amount of each species is approximated as a continuous quantity.
This approach has been extremely useful for describing many systems, but it faces severe limitations when modelling small discrete quantities.
For instance, macromolecules in a cell can be present in a very small amount (\eg{} less than a hundred)\cite{ghaemmaghami_global_2003}.
In such situations, the assumptions of deterministic modelling may fail.
This has been shown to result in quantitative inaccuracy\cite{ale_general_2013}, and, in the worst cases, qualitatively erroneous predictions.


Stochastic modelling has been used as an alternative to deterministic modelling, when these assumptions are violated.
It relies on \gls{cme}, which is a set of differential (or difference) equations providing an \emph{exact} description of a system\cite{kampen_stochastic_2011}.
Except for very simple systems, the \gls{cme} cannot be solved analytically.
However, it is possible to simulate single realisation of the \gls{cme} using \gls{ssa}.
If enough (generally several thousands), simulations are performed, very accurate estimations of the system can be obtained.
Despite extensive effort on increasing the efficiency of such simulations, either by describing new algorithms, or by improving implementations,
they remain too slow for certain problems.
In particular, when trying to infer biological parameters from experimental data, according to an explicit model,
it is necessary to perform many simulations.
In extreme cases, such as for \gls{abc}\cite{toni_approximate_2009}, a very large number of simulations are necessary in order to obtain an 
accurate posterior distributions for parameters.
Therefore, for parameter inference, stochastic simulations are unfortunately critically slow and can rarely be used, even for relatively simple systems.

In order to overcome performance limitations of stochastic simulations whist providing accurate enough results, approximate methods have been used.
\Acrlong{lna}, for instance, 
assumes a probabilistic model for the noise in the stochastic system and then models it by taking in account only the means (first order raw moments), and the variances and covariances (second order central moments)\cite{komorowski_bayesian_2009}.
This method is often limited to cases where the amount of each species is large and systems consist of first order reactions
(such as  $a \rightarrow b$, but not $a + c  \rightarrow b$)\cite{ale_general_2013}.

Another approach aims to expand the \gls{cme} directly by expressing central moments in terms of second or third order central moments\cite{gillespie_moment-closure_2009, gomez-uribe_mass_2007}.
Recently, this concept has been generalised to expand the \gls{cme} up to any arbitrary moment order\cite{ale_general_2013}.
This method, \gls{mea}, has shown very promising results, but has not been investigated in detail yet.

To model the amount of species using \gls{mea}, higher order moments are required to express the lower order moments
(\ie{} the $i^{th}$ moment depends on the $(i+1)^{th}$ moment).
This makes the expressions for central moments (second and higher order moments) infinitely long, and, the \glspl{ode} impossible to solve analytically. 
In order to make the approach computable, a strategy for stopping the
expansion of moment terms by approximating (closing) higher order moments is necessary.

In the original publication\cite{ale_general_2013}, higher order moments were assumed to be zero. 
This approach is elegant mathematically, but may not necessarily be the best one.
If, instead, an assumption is made on the distribution of the species numbers, it is possible
to express any moment in terms of parameters of this distribution\cite{milner_moment_2011}.
Therefore, instead of closing moment expansion with an absolute (scalar) value, the higher order moments can be expressed in
terms of distribution parameters such as mean and variance, which are moments of order one and two. 
It is believed that parametric closure methods may approximate the actual values of the closed moments more accurately.

In principle, \emph{a priori} information on the system can help to decide what type of closure is appropriate for a given system.
Preliminary investigation of this ``parametric moment expansion and closure'' in the context of MEA has been shown to be promising\cite{lakatos_preparation_2014}.

\subsection{Aims of the Project}
\label{sec:aims_of_the_project}

\gls{mea} being a very recent development, no comprehensive implementation has been made available to the community yet.
A \mat{} implementation was developed by the authors of the original publication. A \py{} implementation of \gls{mea} together with \gls{lna}, simulation and parameter inference routines, has also been attempted by the previous year's MSc students\cite{babtie_moment_2013}.
However, both implementations are still prototypical and not ready to be made available to the general public.
 
The aim of our work was to improve and extend existing tools in order to provide a comprehensive publication-ready implementation of \gls{mea}.
We provide \means{}, a \py{} package for Moment Expansion Approximation, iNference and Simulation. 
Here we build on top of the existing functionality in the aforementioned \py{} implementation, aiming to restructure it to make it easier to manage, as well as document it better. 
We also implement the support moment expansion closure using Normal, Log-Normal and Gamma distributions in addition to the original scalar (or zero) closure. Similarly, we provide \gls{ssa} implementation in the package as well as support for different \gls{ode} solvers and additional visualisation functionality.

In the report herein, we explain the decisions that drove the design of the package.
Then, we describe the new re-designed structure of the code that improves it's maintainability.
Afterwards, we provide some examples of intended use in the form of tutorials to the illustrate the usability and the scope of \means.
We then demonstrate how we managed to considerably improve the scalability and performance of the system during the development.
We then go on and use this newly-created package to critically assess \gls{mea}, and address potential limitations.
Finally, we attach the exhaustive documentation for future maintainers and users to the appendix of this document.

\subsection{Author Contributions}
In this section, we attempt to list our respective contribution to the project.
This is a difficult exercise, because we had a very collaborative workflow.
For instance,  two contributors would often be working together on the same part of the package.
In some cases, it was advantageous to write code conjointly (\ie{} pair programming).
In addition, the code written by one author was systematically read, at least, by one peer.
Furthermore,  all authors used  parts of the package made by others.
This allowed to report and fix numerous unforeseen issues.
The same approach was followed for writing the present report and the documentation.
For this reason, we chose to write an exhaustive group report whilst keeping individual ones reasonably concise. 
We realise that this document is therefore quite lengthy.
This is mainly due to the inclusion of tutorials section (\autoref{examples}),
which we debated whether to put in the appendix or the main text. 
We decided, after discussion with our supervisors, that it was appropriate to include it to the main text as it illustrates the scope of our work and should be quick to read due to the writing style. We hope the reader is not discouraged by it.

All authors contributed to understanding -- as much as possible -- the underlying mathematical concepts.
Reforging the package was a collective endeavour which involved considerable input and interaction from all.
The \texttt{core} functionalities such as \texttt{Moment} and \texttt{ODEProblem} objects were also conceptualised and implemented together.  
As mentioned above, all users were involved in providing critical assessment of the work produced by their peers.
Finally, all author took part in writing the documentation of the package.

More specifically, SF and QG worked conjointly on implementing parametric moment closures for \gls{mea}.
SL and SF worked on  investigating limitations of inference together.
SL and QG investigated together the impact of closure distribution and \gls{maxord} on the accuracy and success of the simulation.


SF implemented support for \gls{lna} method and \gls{sbml} standard.
She also wrote most of the large collection of tutorials.
QG was involved in implementing the core of symbolic calculation for \gls{mea}, as well as optimising its performance.
In addition, he implemented support for \gls{ssa}.
SL implemented the core simulation and inference mechanisms and improve their performance.
He was responsible for setting up and maintaining the continuous integration server.
Importantly, SL spend a significant amount of time sharing his software project experience with the rest of the group.


